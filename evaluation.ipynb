{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import load\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import skill_metrics as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('data/train_test/X_test.csv')\n",
    "y_test = pd.read_csv('data/train_test/y_test.csv').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf = load('models/random_forest_pipeline.joblib')\n",
    "pipeline_xgb = load('models/xgboost_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = pipeline_rf.predict(X_test)\n",
    "y_pred_xgb = pipeline_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pred vs actual\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2)\n",
    "plt.title('Random Forest')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_xgb, alpha=0.5)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2)\n",
    "plt.title('XGBoost')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = 100 * np.mean(np.abs((y_true - y_pred) / y_true))\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"R²: {r2:.4f}, MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    return {\"R2\": r2, \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape}\n",
    "\n",
    "# Evaluate both models\n",
    "metrics_rf = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "metrics_xgb = evaluate_model(y_test, y_pred_xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importance = pipeline_rf.named_steps[\"model\"].feature_importances_\n",
    "xgb_importance = pipeline_xgb.named_steps[\"model\"].feature_importances_\n",
    "feature_names = X_test.columns\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=rf_importance, y=feature_names)\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=xgb_importance, y=feature_names)\n",
    "plt.title(\"XGBoost Feature Importance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_rf = y_test - y_pred_rf\n",
    "residuals_xgb = y_test - y_pred_xgb\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(residuals_rf, kde=True, bins=30)\n",
    "plt.title(\"Random Forest Residuals\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(residuals_xgb, kde=True, bins=30)\n",
    "plt.title(\"XGBoost Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"red\")\n",
    "plt.title(\"Random Forest: Predicted vs Actual\")\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_xgb, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color=\"red\")\n",
    "plt.title(\"XGBoost: Predicted vs Actual\")\n",
    "plt.xlabel(\"Actual Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"actual_price\"] = y_test\n",
    "X_test[\"error_rf\"] = np.abs(y_test - y_pred_rf)\n",
    "X_test[\"error_xgb\"] = np.abs(y_test - y_pred_xgb)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=pd.qcut(X_test[\"actual_price\"], q=5), y=X_test[\"error_rf\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Random Forest Error by Price Range\")\n",
    "plt.xlabel(\"Price Range\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=pd.qcut(X_test[\"actual_price\"], q=5), y=X_test[\"error_xgb\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"XGBoost Error by Price Range\")\n",
    "plt.xlabel(\"Price Range\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_heatmap(y_true, y_pred, model_name):\n",
    "    df = pd.DataFrame({\"Actual\": y_true, \"Predicted\": y_pred})\n",
    "    \n",
    "    # Create bins\n",
    "    df[\"Actual Bin\"] = pd.qcut(df[\"Actual\"], q=10)  # Divide actual values into 10 bins\n",
    "    df[\"Predicted Bin\"] = pd.qcut(df[\"Predicted\"], q=10)  # Divide predicted values into 10 bins\n",
    "    \n",
    "    # Create heatmap matrix\n",
    "    heatmap_data = pd.crosstab(df[\"Actual Bin\"], df[\"Predicted Bin\"])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt=\"d\", cmap=\"coolwarm\")\n",
    "    plt.xlabel(\"Predicted Price Range\")\n",
    "    plt.ylabel(\"Actual Price Range\")\n",
    "    plt.title(f\"{model_name} - Error Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "# Generate heatmaps for both models\n",
    "plot_error_heatmap(y_test, y_pred_rf, \"Random Forest\")\n",
    "plot_error_heatmap(y_test, y_pred_xgb, \"XGBoost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_taylor_statistics(y_true, y_preds, model_names):\n",
    "    \"\"\"Calculate statistics required for Taylor Diagram: STD, Correlation, CRMSE.\"\"\"\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    \n",
    "    stats = []\n",
    "    for y_pred, name in zip(y_preds, model_names):\n",
    "        y_pred = np.array(y_pred).flatten()\n",
    "\n",
    "        # Standard Deviation (σ)\n",
    "        std_pred = np.std(y_pred).astype(float)\n",
    "\n",
    "        # Correlation Coefficient (R)\n",
    "        correlation = np.corrcoef(y_true, y_pred)[0, 1]\n",
    "\n",
    "        # Centered Root Mean Square Error (CRMSE)\n",
    "        crmse = np.sqrt(np.mean((y_pred - y_true - np.mean(y_pred - y_true)) ** 2)).astype(float)\n",
    "\n",
    "        stats.append((std_pred, correlation, crmse, name))\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Compute statistics for Random Forest & XGBoost\n",
    "model_names = [\"Random Forest\", \"XGBoost\"]\n",
    "y_preds = [y_pred_rf, y_pred_xgb]\n",
    "taylor_stats = calculate_taylor_statistics(y_test, y_preds, model_names)\n",
    "\n",
    "# Convert values to float to avoid type issues\n",
    "stds = np.array([np.std(y_test)] + [stat[0] for stat in taylor_stats], dtype=float)\n",
    "cors = np.array([1] + [stat[1] for stat in taylor_stats], dtype=float)\n",
    "crmses = np.array([0] + [stat[2] for stat in taylor_stats], dtype=float)\n",
    "labels = [\"Actual\"] + [stat[3] for stat in taylor_stats]\n",
    "\n",
    "# Generate Taylor Diagram\n",
    "sm.taylor_diagram(stds, cors, crmses, markerLabel=labels, colCOR='blue', colSTD='red', alpha=0.7)\n",
    "\n",
    "plt.title(\"Taylor Diagram - Model Comparison\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
