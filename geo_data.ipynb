{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import osmnx as ox\n",
    "import webbrowser\n",
    "import folium\n",
    "from geopy.distance import geodesic\n",
    "from geopy.geocoders import Nominatim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>unemployment_yr_change</th>\n",
       "      <th>cpi_yr_change</th>\n",
       "      <th>real_gdp_yr_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50816.0</td>\n",
       "      <td>59010.065151</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.24</td>\n",
       "      <td>Canton</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>30115.0</td>\n",
       "      <td>3305.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30807.0</td>\n",
       "      <td>14854.018749</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Salem</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>8079.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26201.0</td>\n",
       "      <td>73218.141378</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>75219.0</td>\n",
       "      <td>2807.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19178.0</td>\n",
       "      <td>18177.294285</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.72</td>\n",
       "      <td>Steubenville</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>43952.0</td>\n",
       "      <td>805.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35637.0</td>\n",
       "      <td>69798.320534</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Naples</td>\n",
       "      <td>Florida</td>\n",
       "      <td>34116.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>11</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58988.0</td>\n",
       "      <td>70112.420812</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.06</td>\n",
       "      <td>Finksburg</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>21048.0</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>46344.0</td>\n",
       "      <td>92133.783105</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.75</td>\n",
       "      <td>Aiken</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>29803.0</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>11</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66304.0</td>\n",
       "      <td>18810.139076</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>24523.0</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22654.0</td>\n",
       "      <td>26995.878769</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>2898.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22611.0</td>\n",
       "      <td>8725.101257</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>60621.0</td>\n",
       "      <td>2644.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brokered_by         price  bed  bath  acre_lot          city           state  zip_code  house_size  year  month  unemployment_yr_change  cpi_yr_change  real_gdp_yr_change\n",
       "0      50816.0  59010.065151  4.0   4.0      0.24        Canton         Georgia   30115.0      3305.0  1975      4                     3.8            4.9                -1.8\n",
       "1      30807.0  14854.018749  3.0   1.0      0.40         Salem      New Jersey    8079.0       864.0  1975      4                     3.8            4.9                -1.8\n",
       "2      26201.0  73218.141378  3.0   4.0      0.05        Dallas           Texas   75219.0      2807.0  1975      1                     3.3            5.5                -2.3\n",
       "3      19178.0  18177.294285  2.0   1.0     19.72  Steubenville            Ohio   43952.0       805.0  1975      3                     3.8            4.9                -2.3\n",
       "4      35637.0  69798.320534  3.0   2.0      2.50        Naples         Florida   34116.0      1450.0  1975     11                     1.6            3.8                 2.6\n",
       "5      58988.0  70112.420812  5.0   3.0      3.06     Finksburg        Maryland   21048.0      3501.0  1975      3                     3.8            4.9                -2.3\n",
       "6      46344.0  92133.783105  2.0   3.0      7.75         Aiken  South Carolina   29803.0      1560.0  1975     11                     1.6            3.8                 2.6\n",
       "7      66304.0  18810.139076  3.0   2.0      1.70       Bedford        Virginia   24523.0      1880.0  1975      4                     3.8            4.9                -1.8\n",
       "8      22654.0  26995.878769  3.0   1.0      1.30      Richmond    Rhode Island    2898.0      1224.0  1975      3                     3.8            4.9                -2.3\n",
       "9      22611.0   8725.101257  3.0   2.0      0.08       Chicago        Illinois   60621.0      2644.0  1975      3                     3.8            4.9                -2.3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the data\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df = pd.read_csv('data/real_estate/synthetic_data.csv')\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to iterate over every row of the city, state and zip-code to find the coordinates and append the df with a new \"coordinates\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              city           state  zip_code\n",
      "0           Pinson         Alabama   35126.0\n",
      "1       Fultondale         Alabama   35068.0\n",
      "2       Birmingham         Alabama   35242.0\n",
      "3       Birmingham         Alabama   35216.0\n",
      "4           Pelham         Alabama   35124.0\n",
      "...            ...             ...       ...\n",
      "1195     Charlotte  North Carolina   28209.0\n",
      "1196       Houston           Texas   77084.0\n",
      "1197  East Concord        New York   14055.0\n",
      "1198        Sparks          Nevada   89436.0\n",
      "1199      Lakewood        Illinois   60014.0\n",
      "\n",
      "[1200 rows x 3 columns]\n",
      "Number of rows in Sample df: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8755/2730975796.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_stratified = df.groupby('state', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Assume df is your original DataFrame.\n",
    "# For example, df.columns includes: ['brokered_by', 'status', 'price', 'bed', 'bath', 'acre_lot',\n",
    "# 'street', 'city', 'state', 'zip_code', 'house_size', 'prev_sold_date', ...]\n",
    "\n",
    "# Check if the original DataFrame has at least 1200 rows\n",
    "if len(df) < 1200:\n",
    "    raise ValueError(f\"Original dataset has only {len(df)} rows; cannot sample 1200 unique rows without duplicates.\")\n",
    "\n",
    "# Determine the number of unique states\n",
    "n_states = df['state'].nunique()\n",
    "# Calculate desired number per state (integer division)\n",
    "n_per_state = 1200 // n_states\n",
    "\n",
    "# Stratify by state: For each state, sample up to n_per_state rows without replacement.\n",
    "# (If a state has fewer than n_per_state rows, take all available rows.)\n",
    "df_stratified = df.groupby('state', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(n_per_state, len(x)), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# If the stratified sample has fewer than 1200 rows, then attempt to get additional unique rows.\n",
    "if len(df_stratified) < 1200:\n",
    "    extra_needed = 1200 - len(df_stratified)\n",
    "    # Get the remaining rows that were not selected in the stratified sample.\n",
    "    remaining = df.loc[~df.index.isin(df_stratified.index)]\n",
    "    \n",
    "    if len(remaining) < extra_needed:\n",
    "        # If there aren't enough remaining rows, print a warning.\n",
    "        print(f\"Warning: Only {len(remaining)} remaining rows are available, so you'll have fewer than 1200 unique rows.\")\n",
    "        extra_rows = remaining  # Use all remaining rows.\n",
    "    else:\n",
    "        extra_rows = remaining.sample(n=extra_needed, random_state=42, replace=False)\n",
    "    \n",
    "    df_sample = pd.concat([df_stratified, extra_rows]).reset_index(drop=True)\n",
    "else:\n",
    "    df_sample = df_stratified\n",
    "\n",
    "print(df_sample[['city', 'state', 'zip_code']])\n",
    "print(\"Number of rows in Sample df:\", len(df_sample))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      brokered_by          price  bed  bath  acre_lot          city           state  zip_code  house_size  year  month  unemployment_yr_change  cpi_yr_change  real_gdp_yr_change\n",
      "0         80881.0   59895.804924  4.0   3.0      0.48        Pinson         Alabama   35126.0      2608.0  1986     11                    -0.1          1.400                 2.9\n",
      "1         56101.0   14962.459628  2.0   3.0      0.47    Fultondale         Alabama   35068.0      1435.0  1979     11                     0.0          8.500                 1.3\n",
      "2         53423.0  145233.063316  2.0   3.0      0.02    Birmingham         Alabama   35242.0      1486.0  2013      1                    -0.3          3.615                 1.7\n",
      "3         84178.0   66427.846436  2.0   2.0      0.02    Birmingham         Alabama   35216.0       944.0  2001      3                     0.2          5.000                 2.2\n",
      "4         84184.0   65401.277543  3.0   2.0      0.58        Pelham         Alabama   35124.0      2093.0  1984     12                    -1.0          4.000                 5.6\n",
      "...           ...            ...  ...   ...       ...           ...             ...       ...         ...   ...    ...                     ...            ...                 ...\n",
      "1195      34656.0  254508.440430  2.0   2.0      0.14     Charlotte  North Carolina   28209.0      1273.0  2016      4                    -0.4          2.662                 1.5\n",
      "1196      23220.0  128128.569945  3.0   2.0      0.17       Houston           Texas   77084.0      1836.0  2011      1                    -0.8          3.536                 2.0\n",
      "1197      46190.0   34516.564545  3.0   1.0      3.70  East Concord        New York   14055.0      1904.0  1987      3                    -0.6          3.300                 2.7\n",
      "1198      53553.0  321968.013293  4.0   4.0      0.14        Sparks          Nevada   89436.0      2680.0  2003      1                     0.2          4.600                 1.7\n",
      "1199      30509.0   84013.941721  3.0   4.0      0.05      Lakewood        Illinois   60014.0      2338.0  1989     12                     0.1          5.600                 2.7\n",
      "\n",
      "[1200 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [04:35<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with geocoded coordinates using ArcGIS:\n",
      "              city           state  zip_code                                       full_address   latitude   longitude\n",
      "0           Pinson         Alabama   35126.0            Pinson, Alabama, 35126.0, United States  33.679170  -86.680982\n",
      "1       Fultondale         Alabama   35068.0        Fultondale, Alabama, 35068.0, United States  33.604243  -86.797908\n",
      "2       Birmingham         Alabama   35242.0        Birmingham, Alabama, 35242.0, United States  33.417226  -86.683463\n",
      "3       Birmingham         Alabama   35216.0        Birmingham, Alabama, 35216.0, United States  33.407767  -86.805955\n",
      "4           Pelham         Alabama   35124.0            Pelham, Alabama, 35124.0, United States  33.312978  -86.801347\n",
      "...            ...             ...       ...                                                ...        ...         ...\n",
      "1195     Charlotte  North Carolina   28209.0  Charlotte, North Carolina, 28209.0, United States  35.539344  -79.185418\n",
      "1196       Houston           Texas   77084.0             Houston, Texas, 77084.0, United States  29.841253  -95.660163\n",
      "1197  East Concord        New York   14055.0     East Concord, New York, 14055.0, United States  42.551884  -78.630848\n",
      "1198        Sparks          Nevada   89436.0             Sparks, Nevada, 89436.0, United States  39.587505 -119.725218\n",
      "1199      Lakewood        Illinois   60014.0         Lakewood, Illinois, 60014.0, United States  42.239430  -88.360635\n",
      "\n",
      "[1200 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ssl\n",
    "import certifi\n",
    "from geopy.geocoders import ArcGIS\n",
    "import os\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set the SSL_CERT_FILE environment variable so ArcGIS can verify certificates\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "\n",
    "# Assume df_sample is already defined and has columns: 'city', 'state', 'zip_code'\n",
    "# Ensure a full_address column exists in df_sample:\n",
    "df_sample['full_address'] = (\n",
    "    df_sample['city'] + ', ' +\n",
    "    df_sample['state'] + ', ' +\n",
    "    df_sample['zip_code'].astype(str) + ', United States'\n",
    ")\n",
    "\n",
    "# Initialize the ArcGIS geocoder\n",
    "geolocator = ArcGIS()\n",
    "\n",
    "def geocode_address(addr):\n",
    "    \"\"\"Geocode a single address using ArcGIS with a timeout and a short delay.\"\"\"\n",
    "    try:\n",
    "        location = geolocator.geocode(addr, timeout=10)\n",
    "        time.sleep(0.1)  # Reduced delay between requests; adjust as needed\n",
    "        if location:\n",
    "            return (location.latitude, location.longitude)\n",
    "        else:\n",
    "            return (None, None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error geocoding {addr}: {e}\")\n",
    "        return (None, None)\n",
    "\n",
    "def process_address(addr):\n",
    "    \"\"\"Wrapper function for geocoding an address.\"\"\"\n",
    "    return geocode_address(addr)\n",
    "\n",
    "# Get list of full addresses from the sample\n",
    "addresses = df_sample['full_address'].tolist()\n",
    "\n",
    "# Use ThreadPoolExecutor for parallel processing\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Map process_address function to each address in parallel\n",
    "    results = list(tqdm(executor.map(process_address, addresses), total=len(addresses)))\n",
    "\n",
    "# Unzip the results into separate lists for latitude and longitude\n",
    "latitudes, longitudes = zip(*results)\n",
    "df_sample['latitude'] = latitudes\n",
    "df_sample['longitude'] = longitudes\n",
    "\n",
    "print(\"Data with geocoded coordinates using ArcGIS:\")\n",
    "print(df_sample[['city', 'state', 'zip_code', 'full_address', 'latitude', 'longitude']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great now I will update the amenities code across the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 843/1200 [06:33<07:14,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overpass query error (attempt 1/3): Expecting value: line 1 column 1 (char 0)\n",
      "Overpass query error (attempt 1/3): Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 845/1200 [06:43<11:30,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overpass query error (attempt 1/3): Expecting value: line 1 column 1 (char 0)\n",
      "Overpass query error (attempt 1/3): Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 867/1200 [07:12<07:32,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overpass query error (attempt 1/3): Expecting value: line 1 column 1 (char 0)\n",
      "Overpass query error (attempt 1/3): Expecting value: line 1 column 1 (char 0)\n",
      "Overpass query error (attempt 1/3): Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [11:12<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              city           state  zip_code                                       full_address  amenity_count_500m\n",
      "0           Pinson         Alabama   35126.0            Pinson, Alabama, 35126.0, United States                   0\n",
      "1       Fultondale         Alabama   35068.0        Fultondale, Alabama, 35068.0, United States                   3\n",
      "2       Birmingham         Alabama   35242.0        Birmingham, Alabama, 35242.0, United States                  34\n",
      "3       Birmingham         Alabama   35216.0        Birmingham, Alabama, 35216.0, United States                  29\n",
      "4           Pelham         Alabama   35124.0            Pelham, Alabama, 35124.0, United States                   0\n",
      "...            ...             ...       ...                                                ...                 ...\n",
      "1195     Charlotte  North Carolina   28209.0  Charlotte, North Carolina, 28209.0, United States                   0\n",
      "1196       Houston           Texas   77084.0             Houston, Texas, 77084.0, United States                   2\n",
      "1197  East Concord        New York   14055.0     East Concord, New York, 14055.0, United States                   0\n",
      "1198        Sparks          Nevada   89436.0             Sparks, Nevada, 89436.0, United States                   5\n",
      "1199      Lakewood        Illinois   60014.0         Lakewood, Illinois, 60014.0, United States                   1\n",
      "\n",
      "[1200 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assume df_sample is already defined and includes:\n",
    "# 'city', 'state', 'zip_code', 'full_address', 'latitude', 'longitude'\n",
    "df_sample['full_address'] = (\n",
    "    df_sample['city'] + ', ' +\n",
    "    df_sample['state'] + ', ' +\n",
    "    df_sample['zip_code'].astype(str) + ', United States'\n",
    ")\n",
    "\n",
    "def get_circle_bbox(lat, lon, radius_m=500):\n",
    "    \"\"\"Create a circular buffer around the point and return its bounding box.\"\"\"\n",
    "    point = Point(lon, lat)  # Note: Point takes (lon, lat)\n",
    "    gdf = gpd.GeoDataFrame({'geometry': [point]}, crs='EPSG:4326')\n",
    "    gdf_metric = gdf.to_crs(epsg=3857)\n",
    "    gdf_metric['geometry'] = gdf_metric.buffer(radius_m)\n",
    "    poly = gdf_metric.to_crs(epsg=4326)['geometry'].iloc[0]\n",
    "    return poly.bounds  # (minx, miny, maxx, maxy)\n",
    "\n",
    "def query_overpass(bbox, retries=3, delay=3):\n",
    "    \"\"\"\n",
    "    Query Overpass API for OSM elements with an \"amenity\" tag within the bounding box.\n",
    "    Retries the request up to 'retries' times if it fails to get a valid JSON response.\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = bbox\n",
    "    query = f\"\"\"\n",
    "    [out:json][timeout:25];\n",
    "    (\n",
    "      node[\"amenity\"]({miny},{minx},{maxy},{maxx});\n",
    "      way[\"amenity\"]({miny},{minx},{maxy},{maxx});\n",
    "      relation[\"amenity\"]({miny},{minx},{maxy},{maxx});\n",
    "    );\n",
    "    out center;\n",
    "    \"\"\"\n",
    "    # You can try an alternate Overpass API endpoint if needed:\n",
    "    url = \"http://overpass-api.de/api/interpreter\"\n",
    "    # Alternatively, try:\n",
    "    # url = \"https://lz4.overpass-api.de/api/interpreter\"\n",
    "    \n",
    "    for attempt in range(1, retries+1):\n",
    "        try:\n",
    "            response = requests.get(url, params={'data': query})\n",
    "            if not response.text.strip():\n",
    "                raise ValueError(\"Empty response\")\n",
    "            data = response.json()\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Overpass query error (attempt {attempt}/{retries}): {e}\")\n",
    "            time.sleep(delay)\n",
    "    return {}  # Return an empty dict if all retries fail.\n",
    "\n",
    "def count_overpass_amenities(lat, lon, radius_m=500):\n",
    "    \"\"\"Query Overpass API for a point's buffered area and return the count of amenities.\"\"\"\n",
    "    try:\n",
    "        bbox = get_circle_bbox(lat, lon, radius_m)\n",
    "        data = query_overpass(bbox, retries=3, delay=3)\n",
    "        time.sleep(0.5)  # Short delay between requests\n",
    "        if 'elements' in data:\n",
    "            return len(data['elements'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying amenities for point ({lat}, {lon}): {e}\")\n",
    "    return 0\n",
    "\n",
    "def process_row(row):\n",
    "    return count_overpass_amenities(row.latitude, row.longitude, 500)\n",
    "\n",
    "results = []\n",
    "try:\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        results = list(tqdm(executor.map(process_row, df_sample.itertuples(index=False)), total=len(df_sample)))\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Processing was interrupted by the user.\")\n",
    "\n",
    "if results:\n",
    "    df_sample['amenity_count_500m'] = results\n",
    "    print(df_sample[['city', 'state', 'zip_code', 'full_address', 'amenity_count_500m']])\n",
    "else:\n",
    "    print(\"No results obtained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      brokered_by          price  bed  bath  acre_lot          city           state  zip_code  house_size  year  month  unemployment_yr_change  cpi_yr_change  real_gdp_yr_change                                       full_address   latitude   longitude  amenity_count_500m\n",
      "0         80881.0   59895.804924  4.0   3.0      0.48        Pinson         Alabama   35126.0      2608.0  1986     11                    -0.1          1.400                 2.9            Pinson, Alabama, 35126.0, United States  33.679170  -86.680982                   0\n",
      "1         56101.0   14962.459628  2.0   3.0      0.47    Fultondale         Alabama   35068.0      1435.0  1979     11                     0.0          8.500                 1.3        Fultondale, Alabama, 35068.0, United States  33.604243  -86.797908                   3\n",
      "2         53423.0  145233.063316  2.0   3.0      0.02    Birmingham         Alabama   35242.0      1486.0  2013      1                    -0.3          3.615                 1.7        Birmingham, Alabama, 35242.0, United States  33.417226  -86.683463                  34\n",
      "3         84178.0   66427.846436  2.0   2.0      0.02    Birmingham         Alabama   35216.0       944.0  2001      3                     0.2          5.000                 2.2        Birmingham, Alabama, 35216.0, United States  33.407767  -86.805955                  29\n",
      "4         84184.0   65401.277543  3.0   2.0      0.58        Pelham         Alabama   35124.0      2093.0  1984     12                    -1.0          4.000                 5.6            Pelham, Alabama, 35124.0, United States  33.312978  -86.801347                   0\n",
      "...           ...            ...  ...   ...       ...           ...             ...       ...         ...   ...    ...                     ...            ...                 ...                                                ...        ...         ...                 ...\n",
      "1195      34656.0  254508.440430  2.0   2.0      0.14     Charlotte  North Carolina   28209.0      1273.0  2016      4                    -0.4          2.662                 1.5  Charlotte, North Carolina, 28209.0, United States  35.539344  -79.185418                   0\n",
      "1196      23220.0  128128.569945  3.0   2.0      0.17       Houston           Texas   77084.0      1836.0  2011      1                    -0.8          3.536                 2.0             Houston, Texas, 77084.0, United States  29.841253  -95.660163                   2\n",
      "1197      46190.0   34516.564545  3.0   1.0      3.70  East Concord        New York   14055.0      1904.0  1987      3                    -0.6          3.300                 2.7     East Concord, New York, 14055.0, United States  42.551884  -78.630848                   0\n",
      "1198      53553.0  321968.013293  4.0   4.0      0.14        Sparks          Nevada   89436.0      2680.0  2003      1                     0.2          4.600                 1.7             Sparks, Nevada, 89436.0, United States  39.587505 -119.725218                   5\n",
      "1199      30509.0   84013.941721  3.0   4.0      0.05      Lakewood        Illinois   60014.0      2338.0  1989     12                     0.1          5.600                 2.7         Lakewood, Illinois, 60014.0, United States  42.239430  -88.360635                   1\n",
      "\n",
      "[1200 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.drop(columns='full_address', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of NaN values in the column\n",
    "nan_count = df_sample['amenity_count_500m'].isna().sum()\n",
    "print(\"Number of NaN values:\", nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_csv(\"data/real_estate/synthetic_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
